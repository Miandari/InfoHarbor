{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Assistant with LangGraph - Testing Notebook\n",
    "\n",
    "This notebook tests the functionality of the Information Assistant system built with LangGraph. The assistant provides:\n",
    "\n",
    "- ðŸŽ§ **Podcast Recommendations**: Find podcasts based on interests, topics, or similar to existing podcasts\n",
    "- ðŸ“° **News Updates**: Get recent news on various topics\n",
    "- ðŸ’¬ **Conversational Interface**: Natural language interaction with context retention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's make sure we have the required packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.12/site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain_openai in ./venv/lib/python3.12/site-packages (0.3.16)\n",
      "Requirement already satisfied: tavily-python in ./venv/lib/python3.12/site-packages (0.7.2)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: langgraph in ./venv/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.59)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.42)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in ./venv/lib/python3.12/site-packages (from langchain_openai) (1.78.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./venv/lib/python3.12/site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: httpx in ./venv/lib/python3.12/site-packages (from tavily-python) (0.28.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in ./venv/lib/python3.12/site-packages (from langgraph) (2.0.25)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in ./venv/lib/python3.12/site-packages (from langgraph) (0.1.8)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in ./venv/lib/python3.12/site-packages (from langgraph) (0.1.66)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in ./venv/lib/python3.12/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in ./venv/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./venv/lib/python3.12/site-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx->tavily-python) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx->tavily-python) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain_openai tavily-python python-dotenv requests langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up your API keys in a .env file or directly here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tavily API Key: âœ“ Set\n",
      "OpenAI API Key: âœ“ Set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if API keys are set\n",
    "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(f\"Tavily API Key: {'âœ“ Set' if tavily_key else 'âœ— Not Set'}\")\n",
    "print(f\"OpenAI API Key: {'âœ“ Set' if openai_key else 'âœ— Not Set'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Testing Individual Tools\n",
    "\n",
    "Before we test the full LangGraph workflow, let's test the individual tools to ensure they work correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podcast Tools\n",
    "\n",
    "Let's test the podcast recommendation tools first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import podcast tools from the tools directory\n",
    "from tools.podcast_tools import (\n",
    "    get_podcast_recommendations,\n",
    "    get_podcast_details,\n",
    "    get_similar_podcasts,\n",
    "    get_topic_podcasts,\n",
    "    podcast_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test podcast recommendations\n",
    "print(\"Testing podcast recommendations...\\n\")\n",
    "\n",
    "results = get_podcast_recommendations(\n",
    "    query=\"educational history podcasts about ancient Rome\",\n",
    "    max_results=3,\n",
    "    include_episodes=True\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(f\"Found {results['recommendation_count']} recommendations for '{results['original_query']}'\\n\")\n",
    "\n",
    "for i, podcast in enumerate(results.get('recommendations', []), 1):\n",
    "    print(f\"===== PODCAST {i} =====\")\n",
    "    print(f\"Name: {podcast.get('name', 'Unknown')}\")\n",
    "    print(f\"Publisher: {podcast.get('publisher', 'Unknown')}\")\n",
    "    print(f\"Description: {podcast.get('description', 'No description available')[:150]}...\")\n",
    "    \n",
    "    # Show episodes if available\n",
    "    episodes = podcast.get('episodes', [])\n",
    "    if episodes:\n",
    "        print(\"\\nRecent episodes:\")\n",
    "        for j, episode in enumerate(episodes[:2], 1):\n",
    "            print(f\"  {j}. {episode.get('title', 'Untitled')}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test get podcast details\n",
    "print(\"Testing podcast details lookup...\\n\")\n",
    "\n",
    "# Get details about a specific podcast (using Hardcore History as an example)\n",
    "details = get_podcast_details(podcast_name=\"Hardcore History\")\n",
    "\n",
    "# Display details\n",
    "if details:\n",
    "    podcast = details.get('podcast', {})\n",
    "    print(f\"Title: {podcast.get('title', 'Unknown')}\")\n",
    "    print(f\"Publisher: {podcast.get('publisher', 'Unknown')}\")\n",
    "    print(f\"Description: {podcast.get('description', 'No description')[:200]}...\\n\")\n",
    "    \n",
    "    episodes = podcast.get('episodes', [])\n",
    "    if episodes:\n",
    "        print(\"Recent episodes:\")\n",
    "        for i, episode in enumerate(episodes[:2], 1):\n",
    "            print(f\"  {i}. {episode.get('title', 'Untitled')}\")\n",
    "else:\n",
    "    print(\"No details found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Tools\n",
    "\n",
    "Now let's test the news tools functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import news tools\n",
    "from tools.news_tools import get_recent_news\n",
    "\n",
    "# Test news search\n",
    "print(\"Testing news search...\\n\")\n",
    "\n",
    "topic = \"artificial intelligence\"\n",
    "days_back = 7\n",
    "\n",
    "news_results = get_recent_news(topic=topic, days_back=days_back)\n",
    "\n",
    "# Display results\n",
    "print(f\"Found {news_results.get('article_count', 0)} news articles about '{topic}' in the last {days_back} days\\n\")\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(news_results.get('summary', 'No summary available'))\n",
    "print(\"\\nArticles:\")\n",
    "\n",
    "for i, article in enumerate(news_results.get('articles', []), 1):\n",
    "    print(f\"\\n{i}. {article.get('title', 'No title')}\")\n",
    "    print(f\"   Source: {article.get('source', 'Unknown')}\")\n",
    "    print(f\"   Date: {article.get('date', 'Unknown date')}\")\n",
    "    print(f\"   {article.get('snippet', 'No snippet available')[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Testing the Full LangGraph Workflow\n",
    "\n",
    "Now let's test the complete LangGraph workflow that integrates all tools together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the main workflow\n",
    "from main import run_info_assistant\n",
    "from graph.workflow import create_info_assistant\n",
    "from graph.state import InfoAssistantState\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Also import visualization libraries\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "# Check if graphviz is available\n",
    "try:\n",
    "    from graphviz import Digraph\n",
    "    graphviz_available = True\n",
    "except ImportError:\n",
    "    graphviz_available = False\n",
    "    print(\"Graphviz not installed. Some visualizations may not be available.\")\n",
    "    print(\"Install graphviz using your package manager and pip install graphviz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test basic workflow with a podcast query\n",
    "print(\"Testing workflow with podcast query...\\n\")\n",
    "\n",
    "podcast_query = \"Can you recommend some good history podcasts?\"\n",
    "podcast_response = run_info_assistant(podcast_query)\n",
    "\n",
    "print(f\"Query: {podcast_query}\")\n",
    "print(f\"\\nResponse:\\n{podcast_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test workflow with a news query\n",
    "print(\"Testing workflow with news query...\\n\")\n",
    "\n",
    "news_query = \"What's the latest news about space exploration?\"\n",
    "news_response = run_info_assistant(news_query)\n",
    "\n",
    "print(f\"Query: {news_query}\")\n",
    "print(f\"\\nResponse:\\n{news_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Multi-turn Conversation\n",
    "\n",
    "Let's test a multi-turn conversation to see how the assistant maintains context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conversation ID for this session\n",
    "import uuid\n",
    "conversation_id = str(uuid.uuid4())\n",
    "print(f\"Starting conversation with ID: {conversation_id}\\n\")\n",
    "\n",
    "# First query\n",
    "query1 = \"I'm interested in learning about ancient Rome. Any good podcasts?\"\n",
    "response1 = run_info_assistant(query1, conversation_id=conversation_id)\n",
    "\n",
    "print(f\"User: {query1}\\n\")\n",
    "print(f\"Assistant: {response1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up query referring to the previous response\n",
    "query2 = \"Can you tell me more about the first podcast you mentioned?\"\n",
    "response2 = run_info_assistant(query2, conversation_id=conversation_id)\n",
    "\n",
    "print(f\"User: {query2}\\n\")\n",
    "print(f\"Assistant: {response2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now change topic to news\n",
    "query3 = \"What's been happening in the news about artificial intelligence lately?\"\n",
    "response3 = run_info_assistant(query3, conversation_id=conversation_id)\n",
    "\n",
    "print(f\"User: {query3}\\n\")\n",
    "print(f\"Assistant: {response3}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow up on news\n",
    "query4 = \"Any developments related to AI regulation?\"\n",
    "response4 = run_info_assistant(query4, conversation_id=conversation_id)\n",
    "\n",
    "print(f\"User: {query4}\\n\")\n",
    "print(f\"Assistant: {response4}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the LangGraph Workflow\n",
    "\n",
    "Let's visualize the structure of our LangGraph workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_info_assistant_graph():\n",
    "    \"\"\"Create a visualization of the LangGraph workflow\"\"\"\n",
    "    if not graphviz_available:\n",
    "        from IPython.display import HTML\n",
    "        return HTML(\"\"\"\n",
    "        <div style=\"text-align:center; padding:20px; border:1px solid #ddd; border-radius:5px;\">\n",
    "            <p><b>Graphviz not available</b></p>\n",
    "            <p>Install graphviz to see workflow visualization</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "    # Create visualization\n",
    "    dot = Digraph(comment='Info Assistant Workflow')\n",
    "    dot.attr(rankdir='TB')  # Top to bottom layout\n",
    "    \n",
    "    # Define node styles\n",
    "    dot.attr('node', shape='box', style='filled', fontname='Arial')\n",
    "    \n",
    "    # Add nodes\n",
    "    dot.node('main_agent', 'Main Agent\\n(Router)', fillcolor='lightblue')\n",
    "    dot.node('podcast_tools', 'Podcast Tools', fillcolor='lightyellow')\n",
    "    dot.node('news_tools', 'News Tools', fillcolor='lightgreen')\n",
    "    dot.node('respond', 'Response Handler', fillcolor='lightpink')\n",
    "    dot.node('END', 'END', shape='doublecircle', fillcolor='lightgray')\n",
    "    \n",
    "    # Add edges\n",
    "    dot.edge('main_agent', 'podcast_tools', label='podcast query')\n",
    "    dot.edge('main_agent', 'news_tools', label='news query')\n",
    "    dot.edge('main_agent', 'respond', label='direct response')\n",
    "    dot.edge('main_agent', 'END', label='end conversation')\n",
    "    dot.edge('podcast_tools', 'respond')\n",
    "    dot.edge('news_tools', 'respond')\n",
    "    dot.edge('respond', 'main_agent', label='next turn')\n",
    "    \n",
    "    return dot\n",
    "\n",
    "# Display the visualization\n",
    "graph = visualize_info_assistant_graph()\n",
    "if graphviz_available:\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook has demonstrated:\n",
    "\n",
    "1. Testing the podcast recommendation tools\n",
    "2. Testing the news search tools\n",
    "3. Testing the full LangGraph workflow that integrates both capabilities\n",
    "4. Multi-turn conversations that maintain context\n",
    "5. Visualization of the workflow architecture\n",
    "\n",
    "The Information Assistant successfully combines podcast recommendations and news updates in a conversational interface powered by LangGraph's workflow capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
